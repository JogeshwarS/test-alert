version: '3.8'

services:
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    command:
      - --collector.systemd
    networks:
      - monitoring

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    volumes:
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        wget -qO- ifconfig.me | grep "ip_addr: " | awk '{print $2}' >> /etc/prometheus/ip.txt && \
        IP=`(wget -qO- ifconfig.me | grep "ip_addr: " | awk '{print $2}')` && \
        echo "my ip is : ${IP}" >> /etc/prometheus/ip.txt && \
        echo '
        global:
          scrape_interval: 15s
        alerting:
          alertmanagers:
            - static_configs:
                - targets: ['alertmanager:9093']
        rule_files:
          - "alert_rules.yml"
        scrape_configs:
          - job_name: 'node'
            static_configs:
              - targets: ['node-exporter:9100']
            relabel_configs:
              - source_labels: [__address__]
                target_label: instance
                replacement: "${IP}:9100"
          - job_name: 'prometheus'
            static_configs:
              - targets: ['localhost:9090']
        ' > /etc/prometheus/prometheus.yml && echo '
        groups:
          - name: resource-alerts
            rules:
              - alert: HighCPUUsage
                expr: count_over_time((100 - avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100 > 80)[1h:30s]) > 5
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: "CPU usage is high on {{ $labels.instance }}"
                  description: "CPU usage is above 80% for more than 5 times in last hour."
                  cpu: "{{ printf \"%.2f\" $value }}%"
              - alert: HighMemoryUsage
                expr: count_over_time(((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85)[1h:30s]) > 5
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: "Memory usage is high on {{ $labels.instance }}"
                  description: "Memory usage is above 85% more than 5 times in the last hour."
                  memory: "{{ printf \"%.2f\" $value }}%"
              - alert: HighDiskUsage
                expr: |
                  count_over_time(
                    (
                      (
                        node_filesystem_size_bytes{fstype!~"tmpfs|overlay"} - 
                        node_filesystem_free_bytes{fstype!~"tmpfs|overlay"}
                      ) / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"} * 100 > 85
                    )[1h:30s]
                  ) > 5
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: "Disk usage is high on {{ $labels.instance }}"
                  description: "Disk usage is above 85% more than 5 times in the last hour."
                  disk: "{{ printf \"%.2f\" $value }}%"
        ' > /etc/prometheus/alert_rules.yml && \
        prometheus --config.file=/etc/prometheus/prometheus.yml
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager
    container_name: alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    environment:
      SLACK_CHANNEL: ${SLACK_CHANNEL}
      SLACK_WEBHOOK: ${SLACK_WEBHOOK}
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo '
        global:
          resolve_timeout: 5m
        route:
          receiver: "slack"
          group_by: ["alertname"]
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 3h
        receivers:
          - name: "slack"
            slack_configs:
              - channel: "${SLACK_CHANNEL}"
                api_url: "${SLACK_WEBHOOK}"
                send_resolved: true
                title: "ðŸ”¥ Alert: {{ .CommonLabels.alertname }}"
                text: |
                  {{ range .Alerts }}
                  *Alert:* {{ .Labels.alertname }}
                  *Instance:* {{ .Labels.instance }}
                  *Description:* ```{{ .Annotations.description }}```
                  *Severity:* {{ .Labels.severity }}
                  {{ end }}
        ' > /etc/alertmanager/alertmanager.yml && \
        /bin/alertmanager --config.file=/etc/alertmanager/alertmanager.yml
    networks:
      - monitoring

networks:
  monitoring:
    driver: bridge

volumes:
  prometheus_data: